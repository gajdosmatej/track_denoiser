# track_denoiser
This repository forms the codebase for the paper M. Gajdo≈°, H.N. da Luz, G.G.A. de Souza, M. Bregant, *TPC track denoising and recognition using convolutional neural networks*, CPC (2025), https://doi.org/10.1016/j.cpc.2025.109608.

## Setup on Linux
1. **Create Python virtual environment:** `python3 -m venv .venv` (or possibly just `python` instead of `python3`, depending on the Linux distribution)
2. **Activate the virtual environment:** `source .venv/bin/activate`. This step needs to be applied each time when working with this project.
3. **Install dependencies:** `pip install -r dependencies.txt`.
4. **Create data folders:** If you have access to UTEF-X17 MetaCentrum storage, use the bash script `init_structure_data.sh`, which will also download the measured cosmics data. Otherwise, use the script `init_structure.sh` to construct the correct data folders tree.

## Experimental data
The experimental data are available upon request. Each event is stored in its own `.txt` file, having rows of the form $(x,y,t,E)$, where $E$ stands for the amplitude; coordinates not present in any row are thought as describing zero amplitude. `data/x17/gauge_backgrounds` contain measured events with tracks removed, so that only noisy patterns are present.

## Analysis using the paper neural network
The Jupyter notebook `analysis.ipynb` contains various views, computations and plots regarding the data and neural network results. Most of the plots from the paper should be possible to recreate in this notebook, provided the experimental data are available.

## Synthetised data
For neural network training, synthetised data are being used, generated by `track_generator.py`. Those are stored in `data/simulated/` (denoising/semantic segmentation) and `data/labeling` (track recognition/labeling) either in `clean/` or `noisy/` subdirectories. The generated data are stored in numpy files `<INDEX>.npy` with the integer `INDEX` matching the corresponding clean and noisy files. Each such numpy file contain 5000 generated events, which can be easily adjusted in `track_generator.py`.

The `track_generator.py` admits several flags. To see the list of commands, use `-h`. To specify the number of *batches* (=files, each containing 5000 events), use `-n <INT>`. To specify whether the data are aimed for denoising or track recognition, use `-l <0/1>` (0 for denoising, 1 for recognition). To specify the type of noise employed, use `-m <0/1/2>`, where 0 indicates only synthetic noise, 1 indicates only measured noise masks and 2 indicates mix of both approaches.

In order to use measured noise masks, the experimental data in `data/x17/gauge_backgrounds/` need to be available. If this is not the case, use `-m 0`.

## Neural network training
TODO
### Cluster
TODO

## Pretrained neural network
The pretrained neural network, whose architecture is described in the paper, is stored in several formats in `models/3D/`: 
- The folder `M1/` is the original saved version using the TensorFlow's `SavedModel` format, which is not supported anymore in Keras 3. 
- The files `M1.h5` and `M1.keras` can be both used to load the model even in Keras 3.
- The file `M1.weights.h5` contains the exported weights of the neural network. In order to load these, the network's architecture needs to be specified in the code, but it can be conveniently retrieved using `getPaperModel()` in `classes/modelWrapperClass.py`.
